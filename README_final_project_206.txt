FINAL PROJECT SI 206 
Emma Aboukasm 

PROJECT 1: NATIONAL PARK SERVICE WEBSITE SCRAPER 

DESCRIPTION: 
	This project takes data from the National Parks Service website, saves information into a database and computes states that gain
	the highest revenue from their national parks. It runs off of python and creates a json cached data file, and a database file in
	the process of being run. It requires no user input and is completely self contained. 


HOW TO RUN THIS FILE/DEPENDENCIES: 
	You will need to have Python 3 installed on your computer in order to run this file. Open your terminal window and go to the directory in which you have saved the file. Type in "python 206_final_project" in order to run the file. 

	This file runs using the default parser with Python 3, so no additional moduals need to be installed. 


FILES INCLUDED:

	- 206_final_project.py
	- national_park_cache.json
	- national_park_data.db
	- README_final_project_206.txt (this file)


FUNCTIONS:
	- get_national_park_data():
	
	- get_frontpage_articles():


CLASSES:


DATABASE TABLES:


DATA MANIPULATION:


WHY THIS PROJECT MATTERS TO ME:

	I chose this project because I like the idea of scraping websites for data to make inferences and calculations that will further help people understand things. The world is full of information and it can be overwhelming. But it is important to be able to gather very specific data in order to come up with a better understanding of what may be a complicated issue. This project may be a stepping stone for further data scraping projects in the future. 








